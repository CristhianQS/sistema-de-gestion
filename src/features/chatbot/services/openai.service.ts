/**
 * Servicio de OpenAI para el Chatbot
 *
 * Este servicio maneja todas las interacciones con la API de ChatGPT
 * para hacer el chatbot m√°s inteligente y capaz de entender contexto.
 */

import OpenAI from 'openai';
import { chatbotConfig } from '../config/chatbotPrompts';
import type { Area, AreaField } from '../../../types';

// Inicializar cliente de OpenAI
const openai = new OpenAI({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  dangerouslyAllowBrowser: true // Solo para desarrollo/demo
});

/**
 * Configuraci√≥n de modelos
 */
const MODELS = {
  fast: 'gpt-4o-mini',          // R√°pido y econ√≥mico
  smart: 'gpt-4o',              // M√°s inteligente
  default: 'gpt-4o-mini'        // GPT-4o-mini por defecto
};

/**
 * Verificar si OpenAI est√° configurado
 */
export function isOpenAIEnabled(): boolean {
  return !!import.meta.env.VITE_OPENAI_API_KEY;
}

/**
 * Clasificar autom√°ticamente en qu√© √°rea debe ir el reporte
 *
 * @param mensaje - Descripci√≥n del problema del estudiante
 * @param areas - Lista de √°reas disponibles
 * @returns √çndice del √°rea seleccionada (0-based) o null si no se pudo clasificar
 */
export async function clasificarArea(
  mensaje: string,
  areas: Area[]
): Promise<number | null> {
  try {
    const areasTexto = areas.map((a, i) => `${i}. ${a.name}: ${a.description || 'Sin descripci√≥n'}`).join('\n');

    const prompt = `Eres un asistente de clasificaci√≥n de reportes universitarios.

√ÅREAS DISPONIBLES:
${areasTexto}

PROBLEMA DEL ESTUDIANTE:
"${mensaje}"

INSTRUCCIONES:
1. Lee cuidadosamente el problema
2. Identifica a qu√© √°rea pertenece
3. Responde SOLO con el n√∫mero del √≠ndice (0, 1, 2, etc.)
4. Si no est√°s seguro, responde "-1"

N√∫mero del √°rea:`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [
        {
          role: 'system',
          content: chatbotConfig.sistemPrompts.rol + '\n' + chatbotConfig.sistemPrompts.objetivo
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.3,
      max_tokens: 10
    });

    const resultado = response.choices[0].message.content?.trim();
    const indice = parseInt(resultado || '-1');

    if (indice >= 0 && indice < areas.length) {
      return indice;
    }

    return null;
  } catch (error) {
    console.error('Error al clasificar √°rea con OpenAI:', error);
    return null;
  }
}

/**
 * Extraer informaci√≥n estructurada del mensaje del estudiante
 *
 * @param mensaje - Descripci√≥n completa del problema
 * @returns Objeto con informaci√≥n extra√≠da
 */
export async function extraerInformacion(mensaje: string): Promise<{
  descripcion: string;
  ubicacion: string | null;
  urgencia: 'baja' | 'media' | 'alta';
  categoria: string | null;
}> {
  try {
    const prompt = `Analiza el siguiente reporte de un estudiante y extrae la informaci√≥n clave.

REPORTE:
"${mensaje}"

INSTRUCCIONES:
Extrae:
1. descripcion: Descripci√≥n clara del problema (mejorada si es necesario)
2. ubicacion: Pabell√≥n y sal√≥n si se menciona (o null)
3. urgencia: baja, media o alta seg√∫n la gravedad
4. categoria: Tipo de problema (infraestructura, acad√©mico, tecnolog√≠a, etc.)

Responde en formato JSON v√°lido.`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [
        {
          role: 'system',
          content: 'Eres un asistente experto en extraer informaci√≥n estructurada de reportes universitarios.'
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.2,
      response_format: { type: 'json_object' }
    });

    const resultado = JSON.parse(response.choices[0].message.content || '{}');

    return {
      descripcion: resultado.descripcion || mensaje,
      ubicacion: resultado.ubicacion || null,
      urgencia: resultado.urgencia || 'media',
      categoria: resultado.categoria || null
    };
  } catch (error) {
    console.error('Error al extraer informaci√≥n con OpenAI:', error);
    return {
      descripcion: mensaje,
      ubicacion: null,
      urgencia: 'media',
      categoria: null
    };
  }
}

/**
 * Generar respuesta conversacional inteligente
 *
 * @param conversacionHistorial - Historial de mensajes
 * @param contexto - Contexto actual (alumno, √°rea, etc.)
 * @returns Respuesta generada por ChatGPT
 */
export async function generarRespuesta(
  conversacionHistorial: Array<{ role: 'user' | 'assistant' | 'system'; content: string }>,
  contexto?: {
    alumno?: { nombre: string; codigo: number };
    area?: string;
    paso?: string;
  }
): Promise<string> {
  try {
    const mensajesSistema: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> = [
      {
        role: 'system',
        content: `${chatbotConfig.sistemPrompts.rol}

${chatbotConfig.sistemPrompts.objetivo}

TONO:
${chatbotConfig.sistemPrompts.tono}

RESTRICCIONES:
${chatbotConfig.sistemPrompts.restricciones.map(r => `- ${r}`).join('\n')}

${contexto ? `
CONTEXTO ACTUAL:
${contexto.alumno ? `- Estudiante: ${contexto.alumno.nombre} (${contexto.alumno.codigo})` : ''}
${contexto.area ? `- √Årea seleccionada: ${contexto.area}` : ''}
${contexto.paso ? `- Paso actual: ${contexto.paso}` : ''}
` : ''}`
      }
    ];

    const response = await openai.chat.completions.create({
      model: MODELS.default,
      messages: [...mensajesSistema, ...conversacionHistorial],
      temperature: 0.7,
      max_tokens: 300
    });

    return response.choices[0].message.content || 'Lo siento, no pude procesar tu mensaje.';
  } catch (error) {
    console.error('Error al generar respuesta con OpenAI:', error);
    return 'Lo siento, estoy teniendo problemas t√©cnicos. ¬øPodr√≠as reformular tu pregunta?';
  }
}

/**
 * Responder a saludos de manera natural y solicitar c√≥digo
 *
 * @param mensajeUsuario - Saludo o mensaje inicial del usuario
 * @returns Respuesta amigable + solicitud de c√≥digo
 */
export async function responderSaludo(mensajeUsuario: string): Promise<string> {
  try {
    const prompt = `El usuario te escribi√≥: "${mensajeUsuario}"

Responde de forma BREVE y DIRECTA:
1. Saludo corto (1 l√≠nea)
2. Pide el c√≥digo de estudiante

Ejemplo: "¬°Hola! üëã Bienvenido al Asistente UPEU. ¬øMe das tu c√≥digo de estudiante?"

IMPORTANTE:
- M√°ximo 2 l√≠neas
- Directo al punto
- Sin presentaciones largas

Respuesta:`;

    const response = await openai.chat.completions.create({
      model: MODELS.default,
      messages: [
        {
          role: 'system',
          content: 'Eres un asistente conciso y directo.'
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.7,
      max_tokens: 60
    });

    return response.choices[0].message.content?.trim() ||
      '¬°Hola! üëã ¬øCu√°l es tu c√≥digo de estudiante?';
  } catch (error) {
    console.error('Error al responder saludo con OpenAI:', error);
    return '¬°Hola! üëã ¬øCu√°l es tu c√≥digo de estudiante?';
  }
}

/**
 * Generar respuesta conversacional durante el proceso
 *
 * @param mensajeUsuario - Mensaje del usuario
 * @param pasoActual - En qu√© paso del proceso est√°
 * @param contexto - Informaci√≥n adicional
 * @returns Respuesta natural generada
 */
export async function generarRespuestaContextual(
  mensajeUsuario: string,
  pasoActual: string,
  contexto?: any
): Promise<string> {
  try {
    let instruccion = '';

    switch (pasoActual) {
      case 'waiting_area':
        instruccion = `El usuario debe seleccionar un √°rea. √Åreas disponibles: ${contexto.areas}
Genera una respuesta amigable explicando que debe elegir el n√∫mero del √°rea que corresponda a su problema.`;
        break;

      case 'waiting_description':
        instruccion = `El usuario debe describir su problema en el √°rea: ${contexto.areaNombre}
Genera una respuesta amigable solicitando que describa el problema con detalle (qu√© pas√≥, cu√°ndo, si es urgente).`;
        break;

      case 'waiting_location':
        instruccion = `El usuario debe indicar la ubicaci√≥n del problema.
Genera una respuesta amigable solicitando la ubicaci√≥n espec√≠fica (pabell√≥n, sal√≥n, o lugar del campus).`;
        break;

      default:
        instruccion = 'Genera una respuesta amigable y √∫til.';
    }

    const prompt = `Usuario escribi√≥: "${mensajeUsuario}"

Contexto: ${instruccion}

Genera una respuesta breve (2-3 l√≠neas) que sea:
- Natural y conversacional
- Amigable pero profesional
- Clara sobre lo que necesitas del usuario

Respuesta:`;

    const response = await openai.chat.completions.create({
      model: MODELS.default,
      messages: [
        {
          role: 'system',
          content: chatbotConfig.sistemPrompts.rol + '\n' + chatbotConfig.sistemPrompts.tono
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.7,
      max_tokens: 120
    });

    return response.choices[0].message.content?.trim() || 'Por favor, contin√∫a con la informaci√≥n solicitada.';
  } catch (error) {
    console.error('Error al generar respuesta contextual:', error);
    return 'Por favor, contin√∫a proporcionando la informaci√≥n solicitada.';
  }
}

/**
 * Validar y mejorar la descripci√≥n del problema
 *
 * @param descripcion - Descripci√≥n original
 * @returns Descripci√≥n mejorada
 */
export async function mejorarDescripcion(descripcion: string): Promise<string> {
  try {
    const prompt = `Mejora la siguiente descripci√≥n de un reporte universitario.

DESCRIPCI√ìN ORIGINAL:
"${descripcion}"

INSTRUCCIONES:
1. Corr√≠gela si tiene errores ortogr√°ficos
2. Hazla m√°s clara y espec√≠fica
3. Mant√©n el significado original
4. M√°ximo 2-3 oraciones
5. Usa lenguaje profesional pero amigable

Descripci√≥n mejorada:`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [
        {
          role: 'system',
          content: 'Eres un asistente que mejora descripciones de reportes manteniendo su esencia.'
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.5,
      max_tokens: 150
    });

    return response.choices[0].message.content?.trim() || descripcion;
  } catch (error) {
    console.error('Error al mejorar descripci√≥n con OpenAI:', error);
    return descripcion;
  }
}

/**
 * Sugerir ubicaci√≥n bas√°ndose en el contexto
 *
 * @param mensaje - Mensaje completo del estudiante
 * @returns Ubicaci√≥n sugerida o null
 */
export async function sugerirUbicacion(mensaje: string): Promise<string | null> {
  try {
    const prompt = `Extrae SOLO la ubicaci√≥n mencionada en este mensaje.

MENSAJE:
"${mensaje}"

INSTRUCCIONES:
- Si menciona pabell√≥n y sal√≥n, extr√°elo en formato: "Pabell√≥n X - Sal√≥n Y"
- Si solo menciona pabell√≥n, devuelve: "Pabell√≥n X"
- Si no menciona ubicaci√≥n, responde: "null"
- No inventes informaci√≥n

Ubicaci√≥n:`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.1,
      max_tokens: 30
    });

    const ubicacion = response.choices[0].message.content?.trim();

    if (ubicacion === 'null' || !ubicacion) {
      return null;
    }

    return ubicacion;
  } catch (error) {
    console.error('Error al sugerir ubicaci√≥n con OpenAI:', error);
    return null;
  }
}

/**
 * Detectar si el mensaje es urgente
 *
 * @param mensaje - Mensaje del estudiante
 * @returns true si es urgente, false si no
 */
export async function esUrgente(mensaje: string): Promise<boolean> {
  try {
    const prompt = `Determina si este reporte es URGENTE.

REPORTE:
"${mensaje}"

CRITERIOS DE URGENCIA:
- Riesgo de seguridad (incendio, gas, electricidad)
- Impide el desarrollo de clases
- Da√±o a personas o propiedad
- Emergencia m√©dica

Responde SOLO: "urgente" o "no urgente"`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.2,
      max_tokens: 10
    });

    const resultado = response.choices[0].message.content?.toLowerCase();
    return resultado?.includes('urgente') || false;
  } catch (error) {
    console.error('Error al detectar urgencia con OpenAI:', error);
    return false;
  }
}

/**
 * Generar resumen del reporte
 *
 * @param reporte - Datos completos del reporte
 * @returns Resumen corto
 */
export async function generarResumen(reporte: {
  descripcion: string;
  ubicacion: string;
  area: string;
}): Promise<string> {
  try {
    const prompt = `Resume este reporte en UNA l√≠nea corta (m√°ximo 10 palabras).

REPORTE:
√Årea: ${reporte.area}
Ubicaci√≥n: ${reporte.ubicacion}
Descripci√≥n: ${reporte.descripcion}

Resumen de 10 palabras:`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.3,
      max_tokens: 30
    });

    return response.choices[0].message.content?.trim() || 'Reporte de problema';
  } catch (error) {
    console.error('Error al generar resumen con OpenAI:', error);
    return 'Reporte de problema';
  }
}

/**
 * Detectar √°rea autom√°ticamente bas√°ndose en palabras clave del problema
 * y los campos personalizados de cada √°rea
 *
 * @param mensajeProblema - Descripci√≥n del problema del usuario
 * @param areas - Lista de √°reas disponibles
 * @param areasConCampos - Mapa de campos personalizados por √°rea (opcional)
 * @returns √Årea detectada o null
 */
export async function detectarAreaPorPalabrasClave(
  mensajeProblema: string,
  areas: Area[],
  areasConCampos?: Map<number, AreaField[]>
): Promise<{ area: Area; confianza: number } | null> {
  try {
    // Preparar informaci√≥n de √°reas para el prompt, incluyendo campos personalizados
    const areasInfo = areas.map((a, i) => {
      let info = `${i}. ${a.name}: ${a.description || 'Sin descripci√≥n'}`;

      // Si hay campos personalizados para esta √°rea, incluirlos
      if (areasConCampos && areasConCampos.has(a.id)) {
        const campos = areasConCampos.get(a.id)!;
        // Solo incluir campos tipo SELECT con opciones
        const camposSelect = campos.filter(c => c.field_type === 'select' && c.options);

        if (camposSelect.length > 0) {
          info += '\n   Campos SELECT con opciones:';
          camposSelect.forEach(campo => {
            info += `\n   - ${campo.field_label}`;

            // Incluir opciones del select
            try {
              const options = typeof campo.options === 'string'
                ? JSON.parse(campo.options)
                : campo.options;

              if (Array.isArray(options) && options.length > 0) {
                // Filtrar "default" y opciones vac√≠as
                const validOptions = options.filter(opt =>
                  opt &&
                  opt !== 'default' &&
                  opt.trim() !== ''
                );

                if (validOptions.length > 0) {
                  info += ` ‚Üí OPCIONES: ${validOptions.join(', ')}`;
                }
              }
            } catch (e) {
              // Si hay error al parsear, continuar sin opciones
            }
          });
        }
      }

      return info;
    }).join('\n\n');

    const prompt = `El usuario report√≥ este problema:
"${mensajeProblema}"

√Åreas disponibles con sus campos de formulario:
${areasInfo}

IMPORTANTE - PRIORIDAD DE DETECCI√ìN:
1. **PRIORIDAD M√ÅXIMA**: Busca coincidencias con las OPCIONES de campos tipo SELECT
   - Si encuentras una palabra del problema que coincida EXACTAMENTE con una opci√≥n de un campo select, ESA es el √°rea correcta
   - Ejemplo: Si el usuario dice "cable HDMI" y existe un select con opci√≥n "cable HDMI", usa ESA √°rea

2. **PRIORIDAD MEDIA**: La descripci√≥n del √°rea

3. **PRIORIDAD BAJA**: Los placeholders (son solo ejemplos, NO son criterios de detecci√≥n)

REGLAS ESTRICTAS:
- Las opciones de campos SELECT tienen PRIORIDAD ABSOLUTA sobre cualquier placeholder
- Si una palabra del problema coincide con una opci√≥n de select, ignora los placeholders de otras √°reas
- Los placeholders solo son informativos, NO los uses para detectar el √°rea
- Busca coincidencias parciales: si el usuario dice "hdmi" y hay opci√≥n "cable HDMI", es una coincidencia

Ejemplos:
- Usuario: "cable hdmi" ‚Üí √Årea con select que tiene opci√≥n "cable HDMI" (confianza: 95%)
- Usuario: "proyector" ‚Üí √Årea con select que tiene opci√≥n "proyector" (confianza: 95%)
- NO uses placeholders para decidir, solo las opciones de SELECT

Responde en formato JSON:
{
  "areaIndex": n√∫mero del √°rea (0, 1, 2, etc.),
  "confianza": porcentaje de confianza (0-100),
  "razon": "explicaci√≥n mencionando QU√â OPCI√ìN de QU√â CAMPO SELECT coincidi√≥"
}

Si no est√°s seguro (confianza < 70%), usa areaIndex: -1`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [
        {
          role: 'system',
          content: 'Eres un experto en clasificar problemas universitarios en √°reas espec√≠ficas. Presta especial atenci√≥n a los campos del formulario de cada √°rea, ya que indican qu√© tipo de problemas maneja esa √°rea.'
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.3,
      response_format: { type: 'json_object' }
    });

    const resultado = JSON.parse(response.choices[0].message.content || '{}');

    if (resultado.areaIndex >= 0 && resultado.areaIndex < areas.length && resultado.confianza >= 70) {
      console.log('ü§ñ IA detect√≥ √°rea:', areas[resultado.areaIndex].name, `(${resultado.confianza}% confianza)`);
      console.log('üìù Raz√≥n:', resultado.razon);

      return {
        area: areas[resultado.areaIndex],
        confianza: resultado.confianza
      };
    }

    return null;
  } catch (error) {
    console.error('Error al detectar √°rea:', error);
    return null;
  }
}

/**
 * Extraer informaci√≥n completa del problema para el formulario
 *
 * @param mensajeProblema - Descripci√≥n del problema
 * @param area - √Årea detectada
 * @returns Informaci√≥n estructurada para el formulario
 */
export async function extraerInformacionCompleta(
  mensajeProblema: string,
  area: Area
): Promise<{
  descripcion: string;
  ubicacion: string | null;
  urgencia: 'baja' | 'media' | 'alta';
  detallesAdicionales: any;
}> {
  try {
    const prompt = `El usuario report√≥ este problema en el √°rea "${area.name}":
"${mensajeProblema}"

Extrae la siguiente informaci√≥n en formato JSON:
{
  "descripcion": "descripci√≥n clara y mejorada del problema",
  "ubicacion": "pabell√≥n/sal√≥n espec√≠fico o null si no se menciona",
  "urgencia": "baja/media/alta seg√∫n la gravedad",
  "detallesAdicionales": {
    "palabrasClave": ["palabra1", "palabra2"],
    "tipoProblema": "categor√≠a del problema",
    "requiereAtencionInmediata": true/false
  }
}`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.2,
      response_format: { type: 'json_object' }
    });

    const resultado = JSON.parse(response.choices[0].message.content || '{}');

    return {
      descripcion: resultado.descripcion || mensajeProblema,
      ubicacion: resultado.ubicacion || null,
      urgencia: resultado.urgencia || 'media',
      detallesAdicionales: resultado.detallesAdicionales || {}
    };
  } catch (error) {
    console.error('Error al extraer informaci√≥n completa:', error);
    return {
      descripcion: mensajeProblema,
      ubicacion: null,
      urgencia: 'media',
      detallesAdicionales: {}
    };
  }
}

/**
 * Obtener costos estimados de uso
 */
export function obtenerCostosEstimados() {
  return {
    'gpt-3.5-turbo': {
      input: '$0.0005 / 1K tokens',
      output: '$0.0015 / 1K tokens',
      promedio: '~$0.001 por conversaci√≥n'
    },
    'gpt-4-turbo': {
      input: '$0.01 / 1K tokens',
      output: '$0.03 / 1K tokens',
      promedio: '~$0.02 por conversaci√≥n'
    }
  };
}
