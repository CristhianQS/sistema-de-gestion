/**
 * Servicio de OpenAI para el Chatbot
 *
 * Este servicio maneja todas las interacciones con la API de ChatGPT
 * para hacer el chatbot m치s inteligente y capaz de entender contexto.
 */

import OpenAI from 'openai';
import { chatbotConfig } from '../config/chatbotPrompts';
import type { Area } from '../types';

// Inicializar cliente de OpenAI
const openai = new OpenAI({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  dangerouslyAllowBrowser: true // Solo para desarrollo/demo
});

/**
 * Configuraci칩n de modelos
 */
const MODELS = {
  fast: 'gpt-4o-mini',          // R치pido y econ칩mico
  smart: 'gpt-4o',              // M치s inteligente
  default: 'gpt-4o-mini'        // GPT-4o-mini por defecto
};

/**
 * Verificar si OpenAI est치 configurado
 */
export function isOpenAIEnabled(): boolean {
  return !!import.meta.env.VITE_OPENAI_API_KEY;
}

/**
 * Clasificar autom치ticamente en qu칠 치rea debe ir el reporte
 *
 * @param mensaje - Descripci칩n del problema del estudiante
 * @param areas - Lista de 치reas disponibles
 * @returns 칈ndice del 치rea seleccionada (0-based) o null si no se pudo clasificar
 */
export async function clasificarArea(
  mensaje: string,
  areas: Area[]
): Promise<number | null> {
  try {
    const areasTexto = areas.map((a, i) => `${i}. ${a.name}: ${a.description || 'Sin descripci칩n'}`).join('\n');

    const prompt = `Eres un asistente de clasificaci칩n de reportes universitarios.

츼REAS DISPONIBLES:
${areasTexto}

PROBLEMA DEL ESTUDIANTE:
"${mensaje}"

INSTRUCCIONES:
1. Lee cuidadosamente el problema
2. Identifica a qu칠 치rea pertenece
3. Responde SOLO con el n칰mero del 칤ndice (0, 1, 2, etc.)
4. Si no est치s seguro, responde "-1"

N칰mero del 치rea:`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [
        {
          role: 'system',
          content: chatbotConfig.sistemPrompts.rol + '\n' + chatbotConfig.sistemPrompts.objetivo
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.3,
      max_tokens: 10
    });

    const resultado = response.choices[0].message.content?.trim();
    const indice = parseInt(resultado || '-1');

    if (indice >= 0 && indice < areas.length) {
      return indice;
    }

    return null;
  } catch (error) {
    console.error('Error al clasificar 치rea con OpenAI:', error);
    return null;
  }
}

/**
 * Extraer informaci칩n estructurada del mensaje del estudiante
 *
 * @param mensaje - Descripci칩n completa del problema
 * @returns Objeto con informaci칩n extra칤da
 */
export async function extraerInformacion(mensaje: string): Promise<{
  descripcion: string;
  ubicacion: string | null;
  urgencia: 'baja' | 'media' | 'alta';
  categoria: string | null;
}> {
  try {
    const prompt = `Analiza el siguiente reporte de un estudiante y extrae la informaci칩n clave.

REPORTE:
"${mensaje}"

INSTRUCCIONES:
Extrae:
1. descripcion: Descripci칩n clara del problema (mejorada si es necesario)
2. ubicacion: Pabell칩n y sal칩n si se menciona (o null)
3. urgencia: baja, media o alta seg칰n la gravedad
4. categoria: Tipo de problema (infraestructura, acad칠mico, tecnolog칤a, etc.)

Responde en formato JSON v치lido.`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [
        {
          role: 'system',
          content: 'Eres un asistente experto en extraer informaci칩n estructurada de reportes universitarios.'
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.2,
      response_format: { type: 'json_object' }
    });

    const resultado = JSON.parse(response.choices[0].message.content || '{}');

    return {
      descripcion: resultado.descripcion || mensaje,
      ubicacion: resultado.ubicacion || null,
      urgencia: resultado.urgencia || 'media',
      categoria: resultado.categoria || null
    };
  } catch (error) {
    console.error('Error al extraer informaci칩n con OpenAI:', error);
    return {
      descripcion: mensaje,
      ubicacion: null,
      urgencia: 'media',
      categoria: null
    };
  }
}

/**
 * Generar respuesta conversacional inteligente
 *
 * @param conversacionHistorial - Historial de mensajes
 * @param contexto - Contexto actual (alumno, 치rea, etc.)
 * @returns Respuesta generada por ChatGPT
 */
export async function generarRespuesta(
  conversacionHistorial: Array<{ role: 'user' | 'assistant' | 'system'; content: string }>,
  contexto?: {
    alumno?: { nombre: string; codigo: number };
    area?: string;
    paso?: string;
  }
): Promise<string> {
  try {
    const mensajesSistema: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> = [
      {
        role: 'system',
        content: `${chatbotConfig.sistemPrompts.rol}

${chatbotConfig.sistemPrompts.objetivo}

TONO:
${chatbotConfig.sistemPrompts.tono}

RESTRICCIONES:
${chatbotConfig.sistemPrompts.restricciones.map(r => `- ${r}`).join('\n')}

${contexto ? `
CONTEXTO ACTUAL:
${contexto.alumno ? `- Estudiante: ${contexto.alumno.nombre} (${contexto.alumno.codigo})` : ''}
${contexto.area ? `- 츼rea seleccionada: ${contexto.area}` : ''}
${contexto.paso ? `- Paso actual: ${contexto.paso}` : ''}
` : ''}`
      }
    ];

    const response = await openai.chat.completions.create({
      model: MODELS.default,
      messages: [...mensajesSistema, ...conversacionHistorial],
      temperature: 0.7,
      max_tokens: 300
    });

    return response.choices[0].message.content || 'Lo siento, no pude procesar tu mensaje.';
  } catch (error) {
    console.error('Error al generar respuesta con OpenAI:', error);
    return 'Lo siento, estoy teniendo problemas t칠cnicos. 쯇odr칤as reformular tu pregunta?';
  }
}

/**
 * Responder a saludos de manera natural y solicitar c칩digo
 *
 * @param mensajeUsuario - Saludo o mensaje inicial del usuario
 * @returns Respuesta amigable + solicitud de c칩digo
 */
export async function responderSaludo(mensajeUsuario: string): Promise<string> {
  try {
    const prompt = `El usuario te escribi칩: "${mensajeUsuario}"

Responde de forma BREVE y DIRECTA:
1. Saludo corto (1 l칤nea)
2. Pide el c칩digo de estudiante

Ejemplo: "춰Hola! 游녦 Bienvenido al Asistente UPEU. 쯄e das tu c칩digo de estudiante?"

IMPORTANTE:
- M치ximo 2 l칤neas
- Directo al punto
- Sin presentaciones largas

Respuesta:`;

    const response = await openai.chat.completions.create({
      model: MODELS.default,
      messages: [
        {
          role: 'system',
          content: 'Eres un asistente conciso y directo.'
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.7,
      max_tokens: 60
    });

    return response.choices[0].message.content?.trim() ||
      '춰Hola! 游녦 쮺u치l es tu c칩digo de estudiante?';
  } catch (error) {
    console.error('Error al responder saludo con OpenAI:', error);
    return '춰Hola! 游녦 쮺u치l es tu c칩digo de estudiante?';
  }
}

/**
 * Generar respuesta conversacional durante el proceso
 *
 * @param mensajeUsuario - Mensaje del usuario
 * @param pasoActual - En qu칠 paso del proceso est치
 * @param contexto - Informaci칩n adicional
 * @returns Respuesta natural generada
 */
export async function generarRespuestaContextual(
  mensajeUsuario: string,
  pasoActual: string,
  contexto?: any
): Promise<string> {
  try {
    let instruccion = '';

    switch (pasoActual) {
      case 'waiting_area':
        instruccion = `El usuario debe seleccionar un 치rea. 츼reas disponibles: ${contexto.areas}
Genera una respuesta amigable explicando que debe elegir el n칰mero del 치rea que corresponda a su problema.`;
        break;

      case 'waiting_description':
        instruccion = `El usuario debe describir su problema en el 치rea: ${contexto.areaNombre}
Genera una respuesta amigable solicitando que describa el problema con detalle (qu칠 pas칩, cu치ndo, si es urgente).`;
        break;

      case 'waiting_location':
        instruccion = `El usuario debe indicar la ubicaci칩n del problema.
Genera una respuesta amigable solicitando la ubicaci칩n espec칤fica (pabell칩n, sal칩n, o lugar del campus).`;
        break;

      default:
        instruccion = 'Genera una respuesta amigable y 칰til.';
    }

    const prompt = `Usuario escribi칩: "${mensajeUsuario}"

Contexto: ${instruccion}

Genera una respuesta breve (2-3 l칤neas) que sea:
- Natural y conversacional
- Amigable pero profesional
- Clara sobre lo que necesitas del usuario

Respuesta:`;

    const response = await openai.chat.completions.create({
      model: MODELS.default,
      messages: [
        {
          role: 'system',
          content: chatbotConfig.sistemPrompts.rol + '\n' + chatbotConfig.sistemPrompts.tono
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.7,
      max_tokens: 120
    });

    return response.choices[0].message.content?.trim() || 'Por favor, contin칰a con la informaci칩n solicitada.';
  } catch (error) {
    console.error('Error al generar respuesta contextual:', error);
    return 'Por favor, contin칰a proporcionando la informaci칩n solicitada.';
  }
}

/**
 * Validar y mejorar la descripci칩n del problema
 *
 * @param descripcion - Descripci칩n original
 * @returns Descripci칩n mejorada
 */
export async function mejorarDescripcion(descripcion: string): Promise<string> {
  try {
    const prompt = `Mejora la siguiente descripci칩n de un reporte universitario.

DESCRIPCI칍N ORIGINAL:
"${descripcion}"

INSTRUCCIONES:
1. Corr칤gela si tiene errores ortogr치ficos
2. Hazla m치s clara y espec칤fica
3. Mant칠n el significado original
4. M치ximo 2-3 oraciones
5. Usa lenguaje profesional pero amigable

Descripci칩n mejorada:`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [
        {
          role: 'system',
          content: 'Eres un asistente que mejora descripciones de reportes manteniendo su esencia.'
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.5,
      max_tokens: 150
    });

    return response.choices[0].message.content?.trim() || descripcion;
  } catch (error) {
    console.error('Error al mejorar descripci칩n con OpenAI:', error);
    return descripcion;
  }
}

/**
 * Sugerir ubicaci칩n bas치ndose en el contexto
 *
 * @param mensaje - Mensaje completo del estudiante
 * @returns Ubicaci칩n sugerida o null
 */
export async function sugerirUbicacion(mensaje: string): Promise<string | null> {
  try {
    const prompt = `Extrae SOLO la ubicaci칩n mencionada en este mensaje.

MENSAJE:
"${mensaje}"

INSTRUCCIONES:
- Si menciona pabell칩n y sal칩n, extr치elo en formato: "Pabell칩n X - Sal칩n Y"
- Si solo menciona pabell칩n, devuelve: "Pabell칩n X"
- Si no menciona ubicaci칩n, responde: "null"
- No inventes informaci칩n

Ubicaci칩n:`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.1,
      max_tokens: 30
    });

    const ubicacion = response.choices[0].message.content?.trim();

    if (ubicacion === 'null' || !ubicacion) {
      return null;
    }

    return ubicacion;
  } catch (error) {
    console.error('Error al sugerir ubicaci칩n con OpenAI:', error);
    return null;
  }
}

/**
 * Detectar si el mensaje es urgente
 *
 * @param mensaje - Mensaje del estudiante
 * @returns true si es urgente, false si no
 */
export async function esUrgente(mensaje: string): Promise<boolean> {
  try {
    const prompt = `Determina si este reporte es URGENTE.

REPORTE:
"${mensaje}"

CRITERIOS DE URGENCIA:
- Riesgo de seguridad (incendio, gas, electricidad)
- Impide el desarrollo de clases
- Da침o a personas o propiedad
- Emergencia m칠dica

Responde SOLO: "urgente" o "no urgente"`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.2,
      max_tokens: 10
    });

    const resultado = response.choices[0].message.content?.toLowerCase();
    return resultado?.includes('urgente') || false;
  } catch (error) {
    console.error('Error al detectar urgencia con OpenAI:', error);
    return false;
  }
}

/**
 * Generar resumen del reporte
 *
 * @param reporte - Datos completos del reporte
 * @returns Resumen corto
 */
export async function generarResumen(reporte: {
  descripcion: string;
  ubicacion: string;
  area: string;
}): Promise<string> {
  try {
    const prompt = `Resume este reporte en UNA l칤nea corta (m치ximo 10 palabras).

REPORTE:
츼rea: ${reporte.area}
Ubicaci칩n: ${reporte.ubicacion}
Descripci칩n: ${reporte.descripcion}

Resumen de 10 palabras:`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.3,
      max_tokens: 30
    });

    return response.choices[0].message.content?.trim() || 'Reporte de problema';
  } catch (error) {
    console.error('Error al generar resumen con OpenAI:', error);
    return 'Reporte de problema';
  }
}

/**
 * Detectar 치rea autom치ticamente bas치ndose en palabras clave del problema
 *
 * @param mensajeProblema - Descripci칩n del problema del usuario
 * @param areas - Lista de 치reas disponibles
 * @returns 츼rea detectada o null
 */
export async function detectarAreaPorPalabrasClave(
  mensajeProblema: string,
  areas: Area[]
): Promise<{ area: Area; confianza: number } | null> {
  try {
    // Preparar informaci칩n de 치reas para el prompt
    const areasInfo = areas.map((a, i) => {
      return `${i}. ${a.name}: ${a.description || 'Sin descripci칩n'}`;
    }).join('\n');

    const prompt = `El usuario report칩 este problema:
"${mensajeProblema}"

츼reas disponibles:
${areasInfo}

Analiza el problema y determina qu칠 치rea es la m치s apropiada.

Responde en formato JSON:
{
  "areaIndex": n칰mero del 치rea (0, 1, 2, etc.),
  "confianza": porcentaje de confianza (0-100),
  "razon": "breve explicaci칩n de por qu칠 elegiste esta 치rea"
}

Si no est치s seguro (confianza < 70%), usa areaIndex: -1`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [
        {
          role: 'system',
          content: 'Eres un experto en clasificar problemas universitarios en 치reas espec칤ficas.'
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.3,
      response_format: { type: 'json_object' }
    });

    const resultado = JSON.parse(response.choices[0].message.content || '{}');

    if (resultado.areaIndex >= 0 && resultado.areaIndex < areas.length && resultado.confianza >= 70) {
      console.log('游뱄 IA detect칩 치rea:', areas[resultado.areaIndex].name, `(${resultado.confianza}% confianza)`);
      console.log('游닇 Raz칩n:', resultado.razon);

      return {
        area: areas[resultado.areaIndex],
        confianza: resultado.confianza
      };
    }

    return null;
  } catch (error) {
    console.error('Error al detectar 치rea:', error);
    return null;
  }
}

/**
 * Extraer informaci칩n completa del problema para el formulario
 *
 * @param mensajeProblema - Descripci칩n del problema
 * @param area - 츼rea detectada
 * @returns Informaci칩n estructurada para el formulario
 */
export async function extraerInformacionCompleta(
  mensajeProblema: string,
  area: Area
): Promise<{
  descripcion: string;
  ubicacion: string | null;
  urgencia: 'baja' | 'media' | 'alta';
  detallesAdicionales: any;
}> {
  try {
    const prompt = `El usuario report칩 este problema en el 치rea "${area.name}":
"${mensajeProblema}"

Extrae la siguiente informaci칩n en formato JSON:
{
  "descripcion": "descripci칩n clara y mejorada del problema",
  "ubicacion": "pabell칩n/sal칩n espec칤fico o null si no se menciona",
  "urgencia": "baja/media/alta seg칰n la gravedad",
  "detallesAdicionales": {
    "palabrasClave": ["palabra1", "palabra2"],
    "tipoProblema": "categor칤a del problema",
    "requiereAtencionInmediata": true/false
  }
}`;

    const response = await openai.chat.completions.create({
      model: MODELS.fast,
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.2,
      response_format: { type: 'json_object' }
    });

    const resultado = JSON.parse(response.choices[0].message.content || '{}');

    return {
      descripcion: resultado.descripcion || mensajeProblema,
      ubicacion: resultado.ubicacion || null,
      urgencia: resultado.urgencia || 'media',
      detallesAdicionales: resultado.detallesAdicionales || {}
    };
  } catch (error) {
    console.error('Error al extraer informaci칩n completa:', error);
    return {
      descripcion: mensajeProblema,
      ubicacion: null,
      urgencia: 'media',
      detallesAdicionales: {}
    };
  }
}

/**
 * Obtener costos estimados de uso
 */
export function obtenerCostosEstimados() {
  return {
    'gpt-3.5-turbo': {
      input: '$0.0005 / 1K tokens',
      output: '$0.0015 / 1K tokens',
      promedio: '~$0.001 por conversaci칩n'
    },
    'gpt-4-turbo': {
      input: '$0.01 / 1K tokens',
      output: '$0.03 / 1K tokens',
      promedio: '~$0.02 por conversaci칩n'
    }
  };
}
